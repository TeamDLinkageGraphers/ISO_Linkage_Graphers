{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4254048",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Graph-Based Visualization of Fentanyl Trafficking Networks using AWS Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc27df2",
   "metadata": {},
   "source": [
    "This notebook demonstrates three visualization styles:\n",
    "\n",
    "1. **High-Weight Company Graph** ‚Äì for strong linkages only.\n",
    "2. **Threshold-Based Graph Explorer** ‚Äì filtered and interactive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc83da",
   "metadata": {},
   "source": [
    "## Visualization 1: High-Weight Company Graph\n",
    "**Purpose**: Visualize companies with `Company_Evidence_Weight ‚â• 3000`\n",
    "\n",
    "**Output**: Compact network highlighting strong linkage relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "send_gremlin(\"g.V().drop()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c616d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== Neptune Config ====\n",
    "neptune_endpoint = \"https://db-neptune-2.cluster-c8qttgkgfep5.us-east-1.neptune.amazonaws.com:8182/gremlin\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "threshold = 3000  # Only base companies above this threshold will be included\n",
    "\n",
    "def send_gremlin(query):\n",
    "    payload = {\"gremlin\": query}\n",
    "    try:\n",
    "        response = requests.post(neptune_endpoint, headers=headers, data=json.dumps(payload))\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå {query}\\n{response.text}\")\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Exception: {e}\")\n",
    "        return False\n",
    "\n",
    "# ==== Load and Filter Dataset ====\n",
    "df = pd.read_csv(\"Updated_Top_Companies_with_Evidence_Clean(in).csv\")\n",
    "df_filtered = df[df['Company_Evidence_Weight'] >= threshold].dropna(subset=[\"Company_Evidence_Count\"])\n",
    "\n",
    "# ==== Reset Graph ====\n",
    "print(\"üßπ Clearing existing Neptune graph...\")\n",
    "send_gremlin(\"g.V().drop()\")\n",
    "\n",
    "# ==== Tracking Sets ====\n",
    "base_companies = {}\n",
    "associated_companies = {}\n",
    "linkage_types = set()\n",
    "linkage_values = {}\n",
    "edges = set()\n",
    "\n",
    "# ==== Build Nodes and Relationships ====\n",
    "for _, row in df_filtered.iterrows():\n",
    "    base = row['Base_Consolidation_Name'].strip().replace(\"'\", \"\")\n",
    "    assoc = row['Associated_Company_Name'].strip().replace(\"'\", \"\")\n",
    "    method = row['Linkage_Method'].strip().replace(\"'\", \"\")\n",
    "    value = row['Linkage_Value'].strip().replace(\"'\", \"\")\n",
    "    weight = int(row['Company_Evidence_Weight'])\n",
    "    count = int(row['Company_Evidence_Count'])\n",
    "    assoc_count = int(row['Association_companies_Count'])\n",
    "\n",
    "    lv_key = f\"{method}::{value}\"\n",
    "\n",
    "    # Register unique nodes\n",
    "    base_companies[base] = (base, weight, count, assoc_count)\n",
    "    associated_companies[assoc] = (assoc, weight, count, assoc_count)\n",
    "    linkage_types.add(method)\n",
    "    linkage_values[lv_key] = (method, value)\n",
    "\n",
    "    # Only 1 edge from base ‚ûù type\n",
    "    edges.add((base, 'HAS_TYPE', method))\n",
    "    edges.add((method, 'HAS_VALUE', lv_key))\n",
    "    edges.add((lv_key, 'SHARED_WITH', assoc))\n",
    "\n",
    "# ==== Upload Base Company Nodes ====\n",
    "for name, (n, w, c, a) in tqdm(base_companies.items(), desc=\"Base Companies\"):\n",
    "    q = f\"g.V().has('name', '{n}').fold().coalesce(unfold(), addV('BaseCompany')\" \\\n",
    "        f\".property('name', '{n}').property('evidence_weight', {w})\" \\\n",
    "        f\".property('evidence_count', {c}).property('assoc_count', {a}))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Upload Associated Company Nodes ====\n",
    "for name, (n, w, c, a) in tqdm(associated_companies.items(), desc=\"Associated Companies\"):\n",
    "    q = f\"g.V().has('name', '{n}').fold().coalesce(unfold(), addV('AssociatedCompany')\" \\\n",
    "        f\".property('name', '{n}').property('evidence_weight', {w})\" \\\n",
    "        f\".property('evidence_count', {c}).property('assoc_count', {a}))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Upload Linkage Type Nodes ====\n",
    "for lt in tqdm(linkage_types, desc=\"Linkage Types\"):\n",
    "    q = f\"g.V().has('name', '{lt}').fold().coalesce(unfold(), addV('LinkageType')\" \\\n",
    "        f\".property('name', '{lt}'))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Upload Linkage Value Nodes ====\n",
    "for lv_key, (method, val) in tqdm(linkage_values.items(), desc=\"Linkage Values\"):\n",
    "    q = f\"g.V().has('name', '{lv_key}').fold().coalesce(unfold(), addV('LinkageValue')\" \\\n",
    "        f\".property('name', '{lv_key}').property('method', '{method}').property('value', '{val}'))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Upload All Edges (no duplicates) ====\n",
    "for src, label, dst in tqdm(edges, desc=\"Edges\"):\n",
    "    q = f\"g.V().has('name', '{src}').as('a').V().has('name', '{dst}').addE('{label}').from('a')\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Expand Full Paths ====\n",
    "print(\"üì° Expanding Base ‚ûù Type ‚ûù Value ‚ûù Assoc in Explorer...\")\n",
    "for base in tqdm(base_companies, desc=\"Auto-expanding Graph Explorer\"):\n",
    "    q = f\"g.V().hasLabel('BaseCompany').has('name', '{base}')\" \\\n",
    "        f\".repeat(out().simplePath()).times(3).path()\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "print(\"\\n‚úÖ COMPLETE: Neptune graph is fully interactive and properly hierarchical.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcb94b",
   "metadata": {},
   "source": [
    "## Visualization 2: Threshold-Based Graph Explorer\n",
    "**Purpose**: Focus on companies with evidence weight ‚â• 2000\n",
    "\n",
    "**Output**: Interactive Neptune visualization for investigative navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ccdca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== Neptune Config ====\n",
    "neptune_endpoint = \"https://db-neptune-2.cluster-c8qttgkgfep5.us-east-1.neptune.amazonaws.com:8182/gremlin\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "threshold = 2000  # ‚Üê Updated Threshold for Base Companies\n",
    "\n",
    "def send_gremlin(query):\n",
    "    payload = {\"gremlin\": query}\n",
    "    try:\n",
    "        response = requests.post(neptune_endpoint, headers=headers, data=json.dumps(payload))\n",
    "        if response.status_code != 200:\n",
    "            print(f\"‚ùå {query}\\n{response.text}\")\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Exception: {e}\")\n",
    "        return False\n",
    "\n",
    "# ==== Load and Filter Dataset ====\n",
    "df = pd.read_csv(\"Updated_Top_Companies_with_Evidence_Clean(in).csv\")\n",
    "df_filtered = df[df['Company_Evidence_Weight'] >= threshold].dropna(subset=[\"Company_Evidence_Count\"])\n",
    "\n",
    "# ==== Clear Existing Graph ====\n",
    "print(\"üßπ Dropping old graph...\")\n",
    "send_gremlin(\"g.V().drop()\")\n",
    "\n",
    "# ==== Track All Nodes and Edges ====\n",
    "base_companies = {}\n",
    "associated_companies = {}\n",
    "linkage_types = set()\n",
    "linkage_values = {}\n",
    "edges = set()\n",
    "\n",
    "# ==== Build Graph ====\n",
    "for _, row in df_filtered.iterrows():\n",
    "    base = row['Base_Consolidation_Name'].strip().replace(\"'\", \"\")\n",
    "    assoc = row['Associated_Company_Name'].strip().replace(\"'\", \"\")\n",
    "    method = row['Linkage_Method'].strip().replace(\"'\", \"\")\n",
    "    value = row['Linkage_Value'].strip().replace(\"'\", \"\")\n",
    "    weight = int(row['Company_Evidence_Weight'])\n",
    "    count = int(row['Company_Evidence_Count'])\n",
    "    assoc_count = int(row['Association_companies_Count'])\n",
    "\n",
    "    lv_key = f\"{method}::{value}\"\n",
    "\n",
    "    base_companies[base] = (base, weight, count, assoc_count)\n",
    "    associated_companies[assoc] = (assoc, weight, count, assoc_count)\n",
    "    linkage_types.add(method)\n",
    "    linkage_values[lv_key] = (method, value)\n",
    "\n",
    "    # Edges\n",
    "    edges.add((base, 'HAS_TYPE', method))\n",
    "    edges.add((method, 'HAS_VALUE', lv_key))\n",
    "    edges.add((lv_key, 'SHARED_WITH', assoc))\n",
    "\n",
    "# ==== Insert Base Companies ====\n",
    "for name, (n, w, c, a) in tqdm(base_companies.items(), desc=\"Base Companies\"):\n",
    "    q = f\"g.V().has('name', '{n}').fold().coalesce(unfold(), addV('BaseCompany')\" \\\n",
    "        f\".property('name', '{n}').property('evidence_weight', {w})\" \\\n",
    "        f\".property('evidence_count', {c}).property('assoc_count', {a}))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Insert Associated Companies ====\n",
    "for name, (n, w, c, a) in tqdm(associated_companies.items(), desc=\"Associated Companies\"):\n",
    "    q = f\"g.V().has('name', '{n}').fold().coalesce(unfold(), addV('AssociatedCompany')\" \\\n",
    "        f\".property('name', '{n}').property('evidence_weight', {w})\" \\\n",
    "        f\".property('evidence_count', {c}).property('assoc_count', {a}))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Insert Linkage Types ====\n",
    "for lt in tqdm(linkage_types, desc=\"Linkage Types\"):\n",
    "    q = f\"g.V().has('name', '{lt}').fold().coalesce(unfold(), addV('LinkageType')\" \\\n",
    "        f\".property('name', '{lt}'))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Insert Linkage Values ====\n",
    "for lv_key, (method, val) in tqdm(linkage_values.items(), desc=\"Linkage Values\"):\n",
    "    q = f\"g.V().has('name', '{lv_key}').fold().coalesce(unfold(), addV('LinkageValue')\" \\\n",
    "        f\".property('name', '{lv_key}').property('method', '{method}').property('value', '{val}'))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Insert All Edges (deduped) ====\n",
    "for src, label, dst in tqdm(edges, desc=\"Edges\"):\n",
    "    q = f\"g.V().has('name', '{src}').as('a').V().has('name', '{dst}').addE('{label}').from('a')\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Push to Graph Explorer ====\n",
    "print(\"üì° Expanding Base ‚ûù Type ‚ûù Value ‚ûù Assoc...\")\n",
    "for base in tqdm(base_companies, desc=\"Graph Explorer Path Expansion\"):\n",
    "    q = f\"g.V().hasLabel('BaseCompany').has('name', '{base}')\" \\\n",
    "        f\".repeat(out().simplePath()).times(3).path()\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "print(\"\\n‚úÖ COMPLETE: Graph with threshold ‚â• 200 is now live in Explorer with full expansion!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
