{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4254048",
   "metadata": {},
   "source": [
    "# 📘 Graph-Based Visualization of Fentanyl Trafficking Networks using AWS Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc27df2",
   "metadata": {},
   "source": [
    "This notebook demonstrates three visualization styles:\n",
    "\n",
    "1. **High-Weight Company Graph** – for strong linkages only.\n",
    "2. **Threshold-Based Graph Explorer** – filtered and interactive.\n",
    "3. **Evidence-Tiered Graph** – hierarchical by weight class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc83da",
   "metadata": {},
   "source": [
    "## 1️⃣ Visualization 1: High-Weight Company Graph\n",
    "**Purpose**: Visualize companies with `Company_Evidence_Weight ≥ 3000`\n",
    "\n",
    "**Output**: Compact network highlighting strong linkage relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "send_gremlin(\"g.V().drop()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c616d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== Neptune Config ====\n",
    "neptune_endpoint = \"https://db-neptune-2.cluster-c8qttgkgfep5.us-east-1.neptune.amazonaws.com:8182/gremlin\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "threshold = 3000  # Only base companies above this threshold will be included\n",
    "\n",
    "def send_gremlin(query):\n",
    "    payload = {\"gremlin\": query}\n",
    "    try:\n",
    "        response = requests.post(neptune_endpoint, headers=headers, data=json.dumps(payload))\n",
    "        if response.status_code != 200:\n",
    "            print(f\"❌ {query}\\n{response.text}\")\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception: {e}\")\n",
    "        return False\n",
    "\n",
    "# ==== Load and Filter Dataset ====\n",
    "df = pd.read_csv(\"Updated_Top_Companies_with_Evidence_Clean(in).csv\")\n",
    "df_filtered = df[df['Company_Evidence_Weight'] >= threshold].dropna(subset=[\"Company_Evidence_Count\"])\n",
    "\n",
    "# ==== Reset Graph ====\n",
    "print(\"🧹 Clearing existing Neptune graph...\")\n",
    "send_gremlin(\"g.V().drop()\")\n",
    "\n",
    "# ==== Tracking Sets ====\n",
    "base_companies = {}\n",
    "associated_companies = {}\n",
    "linkage_types = set()\n",
    "linkage_values = {}\n",
    "edges = set()\n",
    "\n",
    "# ==== Build Nodes and Relationships ====\n",
    "for _, row in df_filtered.iterrows():\n",
    "    base = row['Base_Consolidation_Name'].strip().replace(\"'\", \"\")\n",
    "    assoc = row['Associated_Company_Name'].strip().replace(\"'\", \"\")\n",
    "    method = row['Linkage_Method'].strip().replace(\"'\", \"\")\n",
    "    value = row['Linkage_Value'].strip().replace(\"'\", \"\")\n",
    "    weight = int(row['Company_Evidence_Weight'])\n",
    "    count = int(row['Company_Evidence_Count'])\n",
    "    assoc_count = int(row['Association_companies_Count'])\n",
    "\n",
    "    lv_key = f\"{method}::{value}\"\n",
    "\n",
    "    # Register unique nodes\n",
    "    base_companies[base] = (base, weight, count, assoc_count)\n",
    "    associated_companies[assoc] = (assoc, weight, count, assoc_count)\n",
    "    linkage_types.add(method)\n",
    "    linkage_values[lv_key] = (method, value)\n",
    "\n",
    "    # Only 1 edge from base ➝ type\n",
    "    edges.add((base, 'HAS_TYPE', method))\n",
    "    edges.add((method, 'HAS_VALUE', lv_key))\n",
    "    edges.add((lv_key, 'SHARED_WITH', assoc))\n",
    "\n",
    "# ==== Upload Base Company Nodes ====\n",
    "for name, (n, w, c, a) in tqdm(base_companies.items(), desc=\"Base Companies\"):\n",
    "    q = f\"g.V().has('name', '{n}').fold().coalesce(unfold(), addV('BaseCompany')\" \\\n",
    "        f\".property('name', '{n}').property('evidence_weight', {w})\" \\\n",
    "        f\".property('evidence_count', {c}).property('assoc_count', {a}))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Upload Associated Company Nodes ====\n",
    "for name, (n, w, c, a) in tqdm(associated_companies.items(), desc=\"Associated Companies\"):\n",
    "    q = f\"g.V().has('name', '{n}').fold().coalesce(unfold(), addV('AssociatedCompany')\" \\\n",
    "        f\".property('name', '{n}').property('evidence_weight', {w})\" \\\n",
    "        f\".property('evidence_count', {c}).property('assoc_count', {a}))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Upload Linkage Type Nodes ====\n",
    "for lt in tqdm(linkage_types, desc=\"Linkage Types\"):\n",
    "    q = f\"g.V().has('name', '{lt}').fold().coalesce(unfold(), addV('LinkageType')\" \\\n",
    "        f\".property('name', '{lt}'))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Upload Linkage Value Nodes ====\n",
    "for lv_key, (method, val) in tqdm(linkage_values.items(), desc=\"Linkage Values\"):\n",
    "    q = f\"g.V().has('name', '{lv_key}').fold().coalesce(unfold(), addV('LinkageValue')\" \\\n",
    "        f\".property('name', '{lv_key}').property('method', '{method}').property('value', '{val}'))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Upload All Edges (no duplicates) ====\n",
    "for src, label, dst in tqdm(edges, desc=\"Edges\"):\n",
    "    q = f\"g.V().has('name', '{src}').as('a').V().has('name', '{dst}').addE('{label}').from('a')\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Expand Full Paths ====\n",
    "print(\"📡 Expanding Base ➝ Type ➝ Value ➝ Assoc in Explorer...\")\n",
    "for base in tqdm(base_companies, desc=\"Auto-expanding Graph Explorer\"):\n",
    "    q = f\"g.V().hasLabel('BaseCompany').has('name', '{base}')\" \\\n",
    "        f\".repeat(out().simplePath()).times(3).path()\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "print(\"\\n✅ COMPLETE: Neptune graph is fully interactive and properly hierarchical.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcb94b",
   "metadata": {},
   "source": [
    "## 2️⃣ Visualization 2: Threshold-Based Graph Explorer\n",
    "**Purpose**: Focus on companies with evidence weight ≥ 2000\n",
    "\n",
    "**Output**: Interactive Neptune visualization for investigative navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ccdca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== Neptune Config ====\n",
    "neptune_endpoint = \"https://db-neptune-2.cluster-c8qttgkgfep5.us-east-1.neptune.amazonaws.com:8182/gremlin\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "threshold = 2000  # ← Updated Threshold for Base Companies\n",
    "\n",
    "def send_gremlin(query):\n",
    "    payload = {\"gremlin\": query}\n",
    "    try:\n",
    "        response = requests.post(neptune_endpoint, headers=headers, data=json.dumps(payload))\n",
    "        if response.status_code != 200:\n",
    "            print(f\"❌ {query}\\n{response.text}\")\n",
    "        return response.status_code == 200\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception: {e}\")\n",
    "        return False\n",
    "\n",
    "# ==== Load and Filter Dataset ====\n",
    "df = pd.read_csv(\"Updated_Top_Companies_with_Evidence_Clean(in).csv\")\n",
    "df_filtered = df[df['Company_Evidence_Weight'] >= threshold].dropna(subset=[\"Company_Evidence_Count\"])\n",
    "\n",
    "# ==== Clear Existing Graph ====\n",
    "print(\"🧹 Dropping old graph...\")\n",
    "send_gremlin(\"g.V().drop()\")\n",
    "\n",
    "# ==== Track All Nodes and Edges ====\n",
    "base_companies = {}\n",
    "associated_companies = {}\n",
    "linkage_types = set()\n",
    "linkage_values = {}\n",
    "edges = set()\n",
    "\n",
    "# ==== Build Graph ====\n",
    "for _, row in df_filtered.iterrows():\n",
    "    base = row['Base_Consolidation_Name'].strip().replace(\"'\", \"\")\n",
    "    assoc = row['Associated_Company_Name'].strip().replace(\"'\", \"\")\n",
    "    method = row['Linkage_Method'].strip().replace(\"'\", \"\")\n",
    "    value = row['Linkage_Value'].strip().replace(\"'\", \"\")\n",
    "    weight = int(row['Company_Evidence_Weight'])\n",
    "    count = int(row['Company_Evidence_Count'])\n",
    "    assoc_count = int(row['Association_companies_Count'])\n",
    "\n",
    "    lv_key = f\"{method}::{value}\"\n",
    "\n",
    "    base_companies[base] = (base, weight, count, assoc_count)\n",
    "    associated_companies[assoc] = (assoc, weight, count, assoc_count)\n",
    "    linkage_types.add(method)\n",
    "    linkage_values[lv_key] = (method, value)\n",
    "\n",
    "    # Edges\n",
    "    edges.add((base, 'HAS_TYPE', method))\n",
    "    edges.add((method, 'HAS_VALUE', lv_key))\n",
    "    edges.add((lv_key, 'SHARED_WITH', assoc))\n",
    "\n",
    "# ==== Insert Base Companies ====\n",
    "for name, (n, w, c, a) in tqdm(base_companies.items(), desc=\"Base Companies\"):\n",
    "    q = f\"g.V().has('name', '{n}').fold().coalesce(unfold(), addV('BaseCompany')\" \\\n",
    "        f\".property('name', '{n}').property('evidence_weight', {w})\" \\\n",
    "        f\".property('evidence_count', {c}).property('assoc_count', {a}))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Insert Associated Companies ====\n",
    "for name, (n, w, c, a) in tqdm(associated_companies.items(), desc=\"Associated Companies\"):\n",
    "    q = f\"g.V().has('name', '{n}').fold().coalesce(unfold(), addV('AssociatedCompany')\" \\\n",
    "        f\".property('name', '{n}').property('evidence_weight', {w})\" \\\n",
    "        f\".property('evidence_count', {c}).property('assoc_count', {a}))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Insert Linkage Types ====\n",
    "for lt in tqdm(linkage_types, desc=\"Linkage Types\"):\n",
    "    q = f\"g.V().has('name', '{lt}').fold().coalesce(unfold(), addV('LinkageType')\" \\\n",
    "        f\".property('name', '{lt}'))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Insert Linkage Values ====\n",
    "for lv_key, (method, val) in tqdm(linkage_values.items(), desc=\"Linkage Values\"):\n",
    "    q = f\"g.V().has('name', '{lv_key}').fold().coalesce(unfold(), addV('LinkageValue')\" \\\n",
    "        f\".property('name', '{lv_key}').property('method', '{method}').property('value', '{val}'))\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Insert All Edges (deduped) ====\n",
    "for src, label, dst in tqdm(edges, desc=\"Edges\"):\n",
    "    q = f\"g.V().has('name', '{src}').as('a').V().has('name', '{dst}').addE('{label}').from('a')\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "# ==== Push to Graph Explorer ====\n",
    "print(\"📡 Expanding Base ➝ Type ➝ Value ➝ Assoc...\")\n",
    "for base in tqdm(base_companies, desc=\"Graph Explorer Path Expansion\"):\n",
    "    q = f\"g.V().hasLabel('BaseCompany').has('name', '{base}')\" \\\n",
    "        f\".repeat(out().simplePath()).times(3).path()\"\n",
    "    send_gremlin(q)\n",
    "\n",
    "print(\"\\n✅ COMPLETE: Graph with threshold ≥ 200 is now live in Explorer with full expansion!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90679378",
   "metadata": {},
   "source": [
    "## 3️⃣ Visualization 3: Evidence-Tiered Multi-Layer Graph\n",
    "**Purpose**: Categorize companies based on evidence weight ranges\n",
    "\n",
    "**Output**: Hierarchical graph with 3 tiers:\n",
    "- Tier 1: `< 2000`\n",
    "- Tier 2: `2000 - 2999`\n",
    "- Tier 3: `3000+`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e132bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Neptune Config ===\n",
    "neptune_endpoint = \"https://db-neptune-2.cluster-c8qttgkgfep5.us-east-1.neptune.amazonaws.com:8182/gremlin\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# === Dataset Load ===\n",
    "df = pd.read_csv(\"Updated_Top_Companies_with_Evidence_Clean(in).csv\")\n",
    "df = df.dropna(subset=[\"Company_Evidence_Count\"])\n",
    "\n",
    "# === Create Evidence Tiers ===\n",
    "df['Weight_Tier'] = pd.cut(\n",
    "    df['Company_Evidence_Weight'],\n",
    "    bins=[0, 1999, 2999, float('inf')],\n",
    "    labels=[\"< 2000\", \"2000 - 2999\", \"3000+\"],\n",
    "    right=True\n",
    ")\n",
    "\n",
    "# === Gremlin Sender ===\n",
    "def send_gremlin(query, delay=0.1, retries=3):\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            payload = {\"gremlin\": query}\n",
    "            res = requests.post(neptune_endpoint, headers=headers, data=json.dumps(payload), timeout=10)\n",
    "            if res.status_code == 200:\n",
    "                return True\n",
    "            print(f\"Error {res.status_code}: {res.text}\")\n",
    "        except Exception as e:\n",
    "            print(\"Exception:\", e)\n",
    "        time.sleep(delay)\n",
    "    return False\n",
    "\n",
    "# === Drop Graph ===\n",
    "send_gremlin(\"g.V().drop()\")\n",
    "\n",
    "# === Track Nodes ===\n",
    "tiers, base_nodes, assoc_nodes = set(), {}, {}\n",
    "linkage_types, linkage_values, edges = set(), {}, set()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    tier = row['Weight_Tier']\n",
    "    tiers.add(tier)\n",
    "\n",
    "    base = row['Base_Consolidation_Name'].strip().replace(\"'\", \"\")\n",
    "    assoc = row['Associated_Company_Name'].strip().replace(\"'\", \"\")\n",
    "    method = row['Linkage_Method'].strip().replace(\"'\", \"\")\n",
    "    value = row['Linkage_Value'].strip().replace(\"'\", \"\")\n",
    "    lv_key = f\"{method}::{value}\"\n",
    "    \n",
    "    weight = int(row['Company_Evidence_Weight'])\n",
    "    count = int(row['Company_Evidence_Count'])\n",
    "    assoc_count = int(row['Association_companies_Count'])\n",
    "\n",
    "    base_nodes[(tier, base)] = (base, weight, count, assoc_count)\n",
    "    assoc_nodes[(tier, assoc)] = (assoc, weight, count, assoc_count)\n",
    "    linkage_types.add((tier, method))\n",
    "    linkage_values[(tier, lv_key)] = (method, value)\n",
    "\n",
    "    edges.add((tier, 'HAS_BASE', base))\n",
    "    edges.add((base, 'HAS_TYPE', method))\n",
    "    edges.add((method, 'HAS_VALUE', lv_key))\n",
    "    edges.add((lv_key, 'SHARED_WITH', assoc))\n",
    "\n",
    "# === Insert Nodes ===\n",
    "for tier in tiers:\n",
    "    send_gremlin(f\"g.addV('EvidenceTier').property('name', 'Evidence: {tier}')\")\n",
    "\n",
    "for (tier, name), (n, w, c, a) in tqdm(base_nodes.items(), desc=\"Base Companies\"):\n",
    "    send_gremlin(f\"g.addV('BaseCompany').property('name', '{n}')\" +\n",
    "                 f\".property('evidence_weight', {w}).property('evidence_count', {c}).property('assoc_count', {a})\")\n",
    "    send_gremlin(f\"g.V().has('name', 'Evidence: {tier}').as('t')\" +\n",
    "                 f\".V().has('name', '{n}').addE('HAS_BASE').from('t')\")\n",
    "\n",
    "for (tier, name), (n, w, c, a) in tqdm(assoc_nodes.items(), desc=\"Associated Companies\"):\n",
    "    send_gremlin(f\"g.addV('AssociatedCompany').property('name', '{n}')\" +\n",
    "                 f\".property('evidence_weight', {w}).property('evidence_count', {c}).property('assoc_count', {a})\")\n",
    "\n",
    "for (tier, method) in tqdm(linkage_types, desc=\"Linkage Types\"):\n",
    "    send_gremlin(f\"g.addV('LinkageType').property('name', '{method}')\")\n",
    "\n",
    "for (tier, lv_key), (method, val) in tqdm(linkage_values.items(), desc=\"Linkage Values\"):\n",
    "    send_gremlin(f\"g.addV('LinkageValue').property('name', '{lv_key}')\" +\n",
    "                 f\".property('method', '{method}').property('value', '{val}')\")\n",
    "\n",
    "for src, label, dst in tqdm(edges, desc=\"Edges\"):\n",
    "    send_gremlin(f\"g.V().has('name', '{src}').as('a').V().has('name', '{dst}').addE('{label}').from('a')\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# === Auto Expand from Tier ➝ Base ➝ Type ➝ Value ➝ Assoc\n",
    "for tier in tqdm(tiers, desc=\"Expand From Tier\"):\n",
    "    send_gremlin(f\"g.V().hasLabel('EvidenceTier').has('name', 'Evidence: {tier}')\" +\n",
    "                 \".out('HAS_BASE').out().out().out().path()\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
